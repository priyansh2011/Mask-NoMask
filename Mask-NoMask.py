# -*- coding: utf-8 -*-
"""B19CSE067_B19CSE066

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x7oCJ-zFfeITOxB92CNYFmwwIPopJNMf
"""

from __future__ import absolute_import, division, print_function, unicode_literals
import matplotlib.pylab as plt
import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import pandas as pd
import statistics
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Flatten
from keras.layers import MaxPool2D
from keras.layers.convolutional import Conv2D
from sklearn.model_selection import KFold

pd.set_option("display.precision", 8)

from google.colab import drive
drive.mount('/content/drive')

import warnings
warnings.filterwarnings('ignore')

data_root='/content/drive/MyDrive/masknomass/data'

IMAGE_SHAPE = (224, 224)
TRAINING_DATA_DIR = str(data_root)
print(TRAINING_DATA_DIR);
datagen_kwargs = dict(rescale=1./255, validation_split=0.5)
valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)
valid_generator = valid_datagen.flow_from_directory(
TRAINING_DATA_DIR,
subset="validation",
shuffle=True,
target_size=IMAGE_SHAPE
)
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)
train_generator = train_datagen.flow_from_directory(
TRAINING_DATA_DIR,
subset="training",
shuffle=True,
target_size=IMAGE_SHAPE)

image_batch_train, label_batch_train = next(iter(train_generator))
print("Image batch shape: ", image_batch_train.shape)
print("Label batch shape: ", label_batch_train.shape)
dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])
dataset_labels = np.array([key.title() for key, value in dataset_labels])
print(dataset_labels)

for i in range(9):
  plt.subplot(330 + 1 + i)
  plt.imshow(image_batch_train[i])
plt.show()

for i in range(9):
  # plt.subplot(330 + 1 + i)
  print(label_batch_train[i])
  # plt.imshow(image_batch_train[i])
# plt.show()

"""Random Forest on n no of batches of training images"""

from sklearn.ensemble import RandomForestClassifier
rf=RandomForestClassifier()
folds=3
fold_scores=[]

for i in range(folds):
  batches = 0
  for j in range(50): 
        x_batch, y_batch = next(iter(train_generator))
        x_batch=x_batch.reshape(-1,150528)
        rf.fit(x_batch, y_batch)

  each_batch_score=[]
  for j in range(50): 
    x_batch, y_batch = next(iter(valid_generator))
    x_batch=x_batch.reshape(-1,150528)
    each_batch_score.append(rf.score(x_batch,y_batch))
  accuracy=statistics.mean(each_batch_score)

  print(f"Score for fold {i} :", accuracy)
  fold_scores.append(accuracy)

print("Accuracy: ",statistics.mean(fold_scores))

"""KNN"""

from sklearn.neighbors import KNeighborsClassifier
neigh = KNeighborsClassifier(n_neighbors=10)
folds=3
fold_scores=[]

for i in range(folds):
  batches = 0
  for j in range(50): 
      x_batch, y_batch = next(iter(train_generator))
      x_batch=x_batch.reshape(-1,150528)
      neigh.fit(x_batch, y_batch)

  each_batch_score=[]
  for j in range(50): 
      x_batch, y_batch = next(iter(valid_generator))
      x_batch=x_batch.reshape(-1,150528)
      each_batch_score.append(neigh.score(x_batch,y_batch))
  accuracy=statistics.mean(each_batch_score)

  print(f"Score for fold {i} :", accuracy)
  fold_scores.append(accuracy)

print("Accuracy: ",statistics.mean(fold_scores))

"""ADABOOST"""

from sklearn.ensemble import AdaBoostClassifier
clf = AdaBoostClassifier(n_estimators=100, random_state=0)
folds=3
fold_scores=[]

for i in range(folds):
  batches = 0
  for j in range(50): 
        x_batch, y_batch = next(iter(train_generator))
        x_batch=x_batch.reshape(-1,150528)
        y=[]
        for i in y_batch:
          if(i[0]==1):
            y.append(0)
          else:
            y.append(1)
        clf.fit(x_batch, y)

  each_batch_score=[]
  for j in range(50): 
        x_batch, y_batch = next(iter(valid_generator))
        x_batch=x_batch.reshape(-1,150528)
        y=[]
        for i in y_batch:
          if(i[0]==1):
            y.append(0)
          else:
            y.append(1)
        each_batch_score.append(clf.score(x_batch,y))
  accuracy=statistics.mean(each_batch_score)
  print(f"Score for fold {i} :", accuracy)
  fold_scores.append(accuracy)

print("Accuracy: ",statistics.mean(fold_scores))

"""CNN"""

acc_per_fold = []
loss_per_fold = []
#number of folds taken is 3
num_folds=3
kfold = KFold(n_splits=num_folds, shuffle=True)
fold_no = 1
# for train, test in kfold.split(inputs, targets):
  #defining the network
cnn = Sequential()
cnn.add(Conv2D(filters=16, kernel_size=(3,3),input_shape=(224,224,3), activation='relu',))
# cnn.add(Flatten())
cnn.add(MaxPool2D(pool_size=(2, 2)))
cnn.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu',))
cnn.add(MaxPool2D(pool_size=(2, 2)))
cnn.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu',))
cnn.add(MaxPool2D(pool_size=(2, 2)))
cnn.add(Flatten())
cnn.add(Dense(1024, activation='relu'))
cnn.add(Dropout(0.2))
cnn.add(Dense(64, activation='relu'))
cnn.add(Dropout(0.2))
cnn.add(Dense(32, activation='relu'))
cnn.add(Dropout(0.2))
cnn.add(Dense(2, activation='softmax'))
  #compiling the network
cnn.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
  #fitting the network
history=[]
for i in range(num_folds):
     print("Training on Fold: ",i+1)
     history=cnn.fit(train_generator, validation_data=valid_generator,steps_per_epoch=100,epochs=5,validation_steps=100,verbose=1)
     x_batch, y_batch = next(iter(valid_generator))
     score = cnn.evaluate(x_batch, y_batch, verbose=0)
     acc_per_fold.append(score[1] * 100)
     loss_per_fold.append(score[0])
     print(f'Score for fold {i+1}: {cnn.metrics_names[0]} of {score[0]}; {cnn.metrics_names[1]} of {score[1]*100}%')

  #Average results
print('------------------------------------------------------------------------')
print('Score per fold')
for i in range(0, len(acc_per_fold)):
  print('------------------------------------------------------------------------')
  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')
print('------------------------------------------------------------------------')
print('Average scores for all folds:')
print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')
print(f'> Loss: {np.mean(loss_per_fold)}')
print('------------------------------------------------------------------------')

"""MLP"""

acc_per_fold = []
loss_per_fold = []
#number of folds taken is 3
number_folds=3
kfold = KFold(n_splits=number_folds, shuffle=True)
fold_no = 1
mlp = Sequential()
mlp.add(Flatten())
mlp.add(Dense(2050,activation='relu'))
mlp.add(Dropout(0.2))
mlp.add(Dense(1030, activation='relu'))
mlp.add(Dropout(0.2))
mlp.add(Dense(510,activation='relu'))
mlp.add(Dropout(0.2))
mlp.add(Dense(2, activation='softmax'))
#compiling the network
mlp.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
print('------------------------------------------------------------------------')
for i in range(number_folds):
     print("Training on Fold: ",i+1)
     history=mlp.fit(train_generator, validation_data=valid_generator,steps_per_epoch=100,epochs=3,validation_steps=100,verbose=1)
     x_batch, y_batch = next(iter(valid_generator))
     score = mlp.evaluate(x_batch, y_batch, verbose=0)
     acc_per_fold.append(score[1] * 100)
     loss_per_fold.append(score[0])
     print(f'Score for fold {i+1}: {mlp.metrics_names[0]} of {score[0]}; {mlp.metrics_names[1]} of {score[1]*100}%')

  #Average results
print('------------------------------------------------------------------------')
print('Score per fold')
for i in range(0, len(acc_per_fold)):
  print('------------------------------------------------------------------------')
  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')
print('------------------------------------------------------------------------')
print('Average scores for all folds:')
print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')
print(f'> Loss: {np.mean(loss_per_fold)}')
print('------------------------------------------------------------------------')